{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Single major**"
      ],
      "metadata": {
        "id": "7pp7ydV4r6J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "classification_file = '/Users/gahyoungim/Library/CloudStorage/GoogleDrive-dotchgahyoun@gmail.com/내 드라이브/STEM hub-centrality/data/Subject Projected Network/resolution=0.00_community_1_projected_표준분류소계열_stats.xlsx'\n",
        "stem_data_path = '/Users/gahyoungim/Library/CloudStorage/GoogleDrive-dotchgahyoun@gmail.com/내 드라이브/STEM hub-centrality/data/교육과정_대학(20240305)_preprocessed_STEM_fin_with_groups_final.xlsx'\n",
        "\n",
        "# Load Standard Classification (lower) Series data\n",
        "classification_data = pd.read_excel(classification_file)\n",
        "classification_data = classification_data[classification_data['표준분류소계열'] != 'N.C.E.']  # NCE 제외\n",
        "\n",
        "# STEM data load\n",
        "stem_data = pd.read_excel(stem_data_path)\n",
        "stem_data['학교별 학과명'] = stem_data['학교명'] + ' ' + stem_data['학부·과(전공)명']\n",
        "\n",
        "# a list of taxonomy sublines to filter\n",
        "classification_list = classification_data['표준분류소계열'].unique()"
      ],
      "metadata": {
        "id": "N1CytHYDsAMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import re\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "import random\n",
        "\n",
        "# Load and preprocess data\n",
        "stem_data = pd.read_excel(stem_data_path)\n",
        "stem_data['학교별 학과명'] = stem_data['학교명'] + ' ' + stem_data['학부·과(전공)명']\n",
        "stem_data['학점'] = stem_data['학점'].fillna(3)\n",
        "\n",
        "# Theme string normalisation function\n",
        "def normalize_topic(topic):\n",
        "    return re.sub(r'\\d+$', '', topic).strip().lower()\n",
        "\n",
        "# List of banned words\n",
        "excluded_words = {\"none\", \"junior seminars\", \"career\", \"entrepreneurship\", \"internship\",\n",
        "                  \"fieldwork\", \"capstone\", \"writing\", \"field trip\", \"project-based learning\"}\n",
        "\n",
        "# Initial seed subject selection function\n",
        "def determine_initial_courses_single(subfield_data):\n",
        "    unique_credit_sums = subfield_data.groupby(['학교별 학과명', 'Cluster Topic'])['학점'].sum().reset_index()\n",
        "    topic_frequency = unique_credit_sums['Cluster Topic'].value_counts()\n",
        "    mode_credit_sums = unique_credit_sums.groupby('Cluster Topic')['학점'].agg(lambda x: x.mode()[0] if not x.mode().empty else 3)\n",
        "\n",
        "    selected_topics = {}\n",
        "    selected_normalized_topics = set()\n",
        "\n",
        "    for topic, _ in topic_frequency.items():\n",
        "        normalized_topic = normalize_topic(topic)\n",
        "        if normalized_topic not in selected_normalized_topics and topic in mode_credit_sums:\n",
        "            if not any(excluded in normalized_topic for excluded in excluded_words):\n",
        "                selected_topics[topic] = mode_credit_sums[topic]\n",
        "                selected_normalized_topics.add(normalized_topic)\n",
        "        if len(selected_topics) >= 5:\n",
        "            break\n",
        "    return selected_topics, mode_credit_sums\n",
        "\n",
        "# generate bipartite graph function\n",
        "def create_bipartite_graph(subfield_data):\n",
        "    B = nx.Graph()\n",
        "    for _, row in subfield_data.iterrows():\n",
        "        school_dept = f\"학교-{row['학교별 학과명']}\"\n",
        "        cluster_topic = row['Cluster Topic']\n",
        "        credits = row['학점']\n",
        "        B.add_edge(school_dept, cluster_topic, weight=credits)\n",
        "    return B\n",
        "\n",
        "# Project function to Cluster Topic\n",
        "def project_cluster_topic_network(B):\n",
        "    cluster_topic_nodes = {n for n in B.nodes() if not n.startswith(\"학교-\")}\n",
        "    return nx.bipartite.weighted_projected_graph(B, cluster_topic_nodes)\n",
        "\n",
        "# JSD calculation function\n",
        "def calculate_jsd(distribution1, distribution2):\n",
        "    jsd = jensenshannon(distribution1, distribution2, base=2)\n",
        "    return jsd**2\n",
        "\n",
        "# Generate subject distribution function\n",
        "def create_distribution_vector(courses, all_courses):\n",
        "    vector = np.zeros(len(all_courses))\n",
        "    for i, course in enumerate(all_courses):\n",
        "        vector[i] = courses.get(course, 0)\n",
        "    return vector / vector.sum() if vector.sum() != 0 else vector\n",
        "\n",
        "# Calculate network-wide average JSD functio\n",
        "def calculate_average_jsd(selected_topics, subfield_data):\n",
        "    all_courses = subfield_data['Cluster Topic'].unique()\n",
        "    selected_distribution = create_distribution_vector(selected_topics, all_courses)\n",
        "    jsd_scores = []\n",
        "    for dept_name in subfield_data['학교별 학과명'].unique():\n",
        "        dept_courses = subfield_data[subfield_data['학교별 학과명'] == dept_name]\n",
        "        dept_distribution = create_distribution_vector(dept_courses.set_index('Cluster Topic')['학점'].to_dict(), all_courses)\n",
        "        jsd_scores.append(calculate_jsd(selected_distribution, dept_distribution))\n",
        "    return np.mean(jsd_scores)\n",
        "\n",
        "# Single-mode only optimal result generating function\n",
        "def optimized_combination_single(subfield):\n",
        "\n",
        "    subfield_data = stem_data[stem_data['표준분류소계열'] == subfield]\n",
        "    initial_courses, mode_credit_sums = determine_initial_courses_single(subfield_data)\n",
        "    selected_topics = initial_courses.copy()\n",
        "    selected_normalized_topics = {normalize_topic(topic) for topic in selected_topics}\n",
        "\n",
        "    B = create_bipartite_graph(subfield_data)\n",
        "    cluster_topic_projection = project_cluster_topic_network(B)\n",
        "\n",
        "    total_credits = sum(selected_topics.values())\n",
        "    average_sum_of_credits = subfield_data.groupby('학교별 학과명')['학점'].sum().mean()\n",
        "    jsd_ignored_once = False  # flags to ignore JSD and allow adding a subject only once\n",
        "\n",
        "    # Add subject function\n",
        "    def add_course(projection, mode_credit_sums, subfield_data, selected_topics, ignore_jsd=False):\n",
        "        best_jsd, best_topic, best_weight_sum = calculate_average_jsd(selected_topics, subfield_data), None, 0\n",
        "\n",
        "        for topic in projection.nodes:\n",
        "            normalized_topic = normalize_topic(topic)\n",
        "            if normalized_topic in selected_normalized_topics or any(excluded in normalized_topic for excluded in excluded_words):\n",
        "                continue\n",
        "\n",
        "            weight_sum = sum(projection[topic][neighbor]['weight'] for neighbor in selected_topics if projection.has_edge(topic, neighbor))\n",
        "            temp_selected_topics = selected_topics.copy()\n",
        "            temp_selected_topics[topic] = mode_credit_sums.get(topic, 3)\n",
        "            new_jsd = calculate_average_jsd(temp_selected_topics, subfield_data)\n",
        "\n",
        "            # JSD check logic depends on the ignore_jsd flag\n",
        "            if (ignore_jsd or new_jsd < best_jsd) and weight_sum > best_weight_sum:\n",
        "                best_jsd, best_topic, best_weight_sum = new_jsd, topic, weight_sum\n",
        "\n",
        "        if best_topic:\n",
        "            selected_topics[best_topic] = mode_credit_sums.get(best_topic, 3)\n",
        "            selected_normalized_topics.add(normalize_topic(best_topic))\n",
        "            print(f\"Added course '{best_topic}' with weight sum {best_weight_sum} and updated JSD: {best_jsd} (Ignore JSD: {ignore_jsd})\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    # Loop: run until credit requirements are met\n",
        "    while total_credits < min(0.85 * average_sum_of_credits, 85):\n",
        "        if total_credits > min(0.85 * average_sum_of_credits, 85):\n",
        "            break\n",
        "        # attempt to add a subject taking JSD into account\n",
        "        added = add_course(cluster_topic_projection, mode_credit_sums, subfield_data, selected_topics)\n",
        "\n",
        "        # If no subjects have been added, credits are less than 0.5*average credits, and the JSD ignore add has never been executed\n",
        "        if not added and total_credits < 0.5 * average_sum_of_credits and not jsd_ignored_once:\n",
        "            # Add a subject by allowing JSD override only once\n",
        "            added = add_course(cluster_topic_projection, mode_credit_sums, subfield_data, selected_topics, ignore_jsd=True)\n",
        "            jsd_ignored_once = True  # set the flag to run only once\n",
        "\n",
        "        # exit the loop if there are no subjects to add\n",
        "        if not added:\n",
        "            print(\"No further course addition possible. Exiting loop.\")\n",
        "            break\n",
        "\n",
        "\n",
        "        total_credits = sum(selected_topics.values())\n",
        "\n",
        "    final_topics_df = pd.DataFrame({\n",
        "        \"Course\": list(selected_topics.keys()),\n",
        "        \"Credits\": list(selected_topics.values())\n",
        "    })\n",
        "\n",
        "    print(final_topics_df)\n",
        "    print(f\"Final Total Credits: {total_credits}\")\n",
        "    return final_topics_df"
      ],
      "metadata": {
        "id": "cn_HNY0esDa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "# Create a list of series sorted in Korean order except for ‘N.C.E.’\n",
        "sorted_subfields = sorted([subfield for subfield in stem_data['표준분류소계열'].unique() if subfield != \"N.C.E.\"])\n",
        "\n",
        "# Calculate the optimised combinations for each series and save the results to an Excel file\n",
        "for target_subfield in sorted_subfields:\n",
        "    print(f\"Processing subfield: {target_subfield}\")\n",
        "\n",
        "    # Calculate the optimised combinations for each series and save the results to an Excel file\n",
        "    result_df = optimized_combination_single(target_subfield)\n",
        "\n",
        "    # Save the results to an Excel file\n",
        "    filename = f'/Users/gahyoungim/Library/CloudStorage/GoogleDrive-dotchgahyoun@gmail.com/내 드라이브/Curriculum Analysis Project/K-STEM Curriculum Network Analysis/Interdisciplinary Majors/single major jsd base/{target_subfield}_single_major.xlsx'\n",
        "    with pd.ExcelWriter(filename) as writer:\n",
        "        result_df.to_excel(writer, sheet_name=\"Courses and Credits\", index=False)\n",
        "\n",
        "    print(f\"Saved {filename}\")"
      ],
      "metadata": {
        "id": "eOGyUvVKsEVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Double major**"
      ],
      "metadata": {
        "id": "7IRBmGGFsMLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import re\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "# Load and preprocess data\n",
        "stem_data = pd.read_excel('/home/hedgehog/Interdisciplinary Majors/교육과정_대학(20240305)_preprocessed_STEM_fin_with_groups_final.xlsx')\n",
        "stem_data['학교별 학과명'] = stem_data['학교명'] + ' ' + stem_data['학부·과(전공)명']\n",
        "stem_data['학점'] = stem_data['학점'].fillna(3)\n",
        "\n",
        "# Theme string normalisation function\n",
        "def normalize_topic(topic):\n",
        "    if pd.isna(topic):   # Prevent NaN\n",
        "        return ''\n",
        "    return re.sub(r'\\d+$', '', str(topic)).strip().lower()\n",
        "\n",
        "# List of banned words\n",
        "excluded_words = {\"none\", \"junior seminars\", \"career\", \"entrepreneurship\", \"internship\",\n",
        "                  \"fieldwork\", \"capstone\", \"writing\", \"field trip\", \"project-based learning\"}\n",
        "\n",
        "# Initial subject selection function\n",
        "def determine_initial_courses_single(subfield_data):\n",
        "    if subfield_data.empty:  # Handle empty dataframes\n",
        "        return {}, pd.Series(dtype=float)\n",
        "\n",
        "    unique_credit_sums = subfield_data.groupby(['학교별 학과명', 'Cluster Topic'])['학점'].sum().reset_index()\n",
        "    topic_frequency = unique_credit_sums['Cluster Topic'].value_counts()\n",
        "\n",
        "    # Process empty data\n",
        "    mode_credit_sums = unique_credit_sums.groupby('Cluster Topic')['학점'].agg(\n",
        "        lambda x: x.mode()[0] if not x.mode().empty else 3  # Prevent empty arrays\n",
        "    )\n",
        "\n",
        "    selected_topics = {}\n",
        "    selected_normalized_topics = set()\n",
        "\n",
        "    for topic, _ in topic_frequency.items():\n",
        "        normalized_topic = normalize_topic(topic)\n",
        "        if normalized_topic not in selected_normalized_topics and topic in mode_credit_sums:\n",
        "            if not any(excluded in normalized_topic for excluded in excluded_words):\n",
        "                selected_topics[topic] = mode_credit_sums[topic]\n",
        "                selected_normalized_topics.add(normalized_topic)\n",
        "        if len(selected_topics) >= 5:\n",
        "            break\n",
        "\n",
        "    return selected_topics, mode_credit_sums\n",
        "\n",
        "# Calculate network-wide average JSD function\n",
        "def calculate_average_jsd(selected_topics, subfield_data):\n",
        "    all_courses = subfield_data['Cluster Topic'].unique()\n",
        "    selected_distribution = create_distribution_vector(selected_topics, all_courses)\n",
        "    jsd_scores = []\n",
        "\n",
        "    for dept_name in subfield_data['학교별 학과명'].unique():\n",
        "        dept_courses = subfield_data[subfield_data['학교별 학과명'] == dept_name]\n",
        "        dept_distribution = create_distribution_vector(\n",
        "            dept_courses.groupby('Cluster Topic')['학점'].sum().to_dict(),\n",
        "            all_courses\n",
        "        )\n",
        "        jsd_scores.append(calculate_jsd(selected_distribution, dept_distribution))\n",
        "\n",
        "    return np.mean(jsd_scores)\n",
        "\n",
        "# generate bipartite graph function\n",
        "def create_bipartite_graph(subfield_data):\n",
        "    B = nx.Graph()\n",
        "    for _, row in subfield_data.iterrows():\n",
        "        school_dept = f\"학교-{row['학교별 학과명']}\"\n",
        "        cluster_topic = row['Cluster Topic']\n",
        "        credits = row['학점']\n",
        "        B.add_edge(school_dept, cluster_topic, weight=credits)\n",
        "    return B\n",
        "\n",
        "# Project function to Cluster Topic\n",
        "def project_cluster_topic_network(B):\n",
        "    cluster_topic_nodes = {n for n in B.nodes() if not n.startswith(\"학교-\")}\n",
        "    return nx.bipartite.weighted_projected_graph(B, cluster_topic_nodes)\n",
        "\n",
        "# JSD calculation function\n",
        "def calculate_jsd(distribution1, distribution2):\n",
        "    # Handle if distribution is empty\n",
        "    if distribution1.sum() == 0 or distribution2.sum() == 0:\n",
        "        return 1.0  # Return the maximum distance (if the distribution is non-normal)\n",
        "    jsd = jensenshannon(distribution1, distribution2, base=2)\n",
        "    return jsd**2\n",
        "\n",
        "\n",
        "# Generate subject distribution function\n",
        "def create_distribution_vector(courses, all_courses):\n",
        "    vector = np.zeros(len(all_courses))\n",
        "    for i, course in enumerate(all_courses):\n",
        "        vector[i] = courses.get(course, 0)\n",
        "    total_sum = vector.sum()\n",
        "    return vector / total_sum if total_sum != 0 else vector  # return as is if denominator is zero\n",
        "\n",
        "\n",
        "# Calculate network-wide average JSD function\n",
        "def calculate_average_jsd(selected_topics, subfield_data):\n",
        "    all_courses = subfield_data['Cluster Topic'].unique()\n",
        "    selected_distribution = create_distribution_vector(selected_topics, all_courses)\n",
        "    jsd_scores = []\n",
        "    for dept_name in subfield_data['학교별 학과명'].unique():\n",
        "        dept_courses = subfield_data[subfield_data['학교별 학과명'] == dept_name]\n",
        "        dept_distribution = create_distribution_vector(dept_courses.set_index('Cluster Topic')['학점'].to_dict(), all_courses)\n",
        "        jsd_scores.append(calculate_jsd(selected_distribution, dept_distribution))\n",
        "    return np.mean(jsd_scores)\n",
        "\n",
        "# single-mode only optimisation function\n",
        "def optimized_combination_single(subfield):\n",
        "\n",
        "    subfield_data = stem_data[stem_data['표준분류소계열'] == subfield]\n",
        "    initial_courses, mode_credit_sums = determine_initial_courses_single(subfield_data)\n",
        "    selected_topics = initial_courses.copy()\n",
        "    selected_normalized_topics = {normalize_topic(topic) for topic in selected_topics}\n",
        "\n",
        "    B = create_bipartite_graph(subfield_data)\n",
        "    cluster_topic_projection = project_cluster_topic_network(B)\n",
        "\n",
        "    total_credits = sum(selected_topics.values())\n",
        "    average_sum_of_credits = subfield_data.groupby('학교별 학과명')['학점'].sum().mean()\n",
        "    jsd_ignored_once = False  # flags to ignore JSD and allow adding a subject only once\n",
        "\n",
        "    # Add subject function\n",
        "    def add_course(projection, mode_credit_sums, subfield_data, selected_topics, ignore_jsd=False):\n",
        "        best_jsd, best_topic, best_weight_sum = calculate_average_jsd(selected_topics, subfield_data), None, 0\n",
        "\n",
        "        for topic in projection.nodes:\n",
        "            normalized_topic = normalize_topic(topic)\n",
        "            if normalized_topic in selected_normalized_topics or any(excluded in normalized_topic for excluded in excluded_words):\n",
        "                continue\n",
        "\n",
        "            # Calculate the sum of the weights\n",
        "            weight_sum = sum(\n",
        "                projection[topic][neighbor]['weight'] for neighbor in selected_topics if projection.has_edge(topic, neighbor)\n",
        "            )\n",
        "            temp_selected_topics = selected_topics.copy()\n",
        "            temp_selected_topics[topic] = mode_credit_sums.get(topic, 3)\n",
        "            new_jsd = calculate_average_jsd(temp_selected_topics, subfield_data)\n",
        "\n",
        "            if (ignore_jsd or new_jsd < best_jsd) and weight_sum > best_weight_sum:\n",
        "                best_jsd, best_topic, best_weight_sum = new_jsd, topic, weight_sum\n",
        "\n",
        "        if best_topic:\n",
        "            selected_topics[best_topic] = mode_credit_sums.get(best_topic, 3)\n",
        "            selected_normalized_topics.add(normalize_topic(best_topic))\n",
        "            print(f\"Added course '{best_topic}' with weight sum {best_weight_sum} and updated JSD: {best_jsd} (Ignore JSD: {ignore_jsd})\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    # Loop: run until credit requirements are met\n",
        "    while total_credits < min(0.85 * average_sum_of_credits, 85):\n",
        "        if total_credits > min(0.85 * average_sum_of_credits, 85):\n",
        "            break\n",
        "        # attempt to add a subject taking JSD into account\n",
        "        added = add_course(cluster_topic_projection, mode_credit_sums, subfield_data, selected_topics)\n",
        "\n",
        "        # if no subjects have been added, credits are less than 0.5*average credits, and the JSD ignore add has never been executed\n",
        "        if not added and total_credits < 0.5 * average_sum_of_credits and not jsd_ignored_once:\n",
        "            # Add a subject by allowing JSD override only once\n",
        "            added = add_course(cluster_topic_projection, mode_credit_sums, subfield_data, selected_topics, ignore_jsd=True)\n",
        "            jsd_ignored_once = True  # set the flag to run only once\n",
        "\n",
        "        # exit the loop if there are no subjects to add\n",
        "        if not added:\n",
        "            print(\"No further course addition possible. Exiting loop.\")\n",
        "            break\n",
        "\n",
        "\n",
        "        total_credits = sum(selected_topics.values())\n",
        "\n",
        "    final_topics_df = pd.DataFrame({\n",
        "        \"Course\": list(selected_topics.keys()),\n",
        "        \"Credits\": list(selected_topics.values())\n",
        "    })\n",
        "\n",
        "    print(final_topics_df)\n",
        "    print(f\"Final Total Credits: {total_credits}\")\n",
        "    return final_topics_df\n",
        "\n",
        "def optimized_combination_double(subfield1, subfield2):\n",
        "    random.seed(42)  # set random seed\n",
        "\n",
        "    # Extract two series data\n",
        "    subfield_data1 = stem_data[stem_data['표준분류소계열'] == subfield1]\n",
        "    subfield_data2 = stem_data[stem_data['표준분류소계열'] == subfield2]\n",
        "    combined_data = pd.concat([subfield_data1, subfield_data2], ignore_index=True)\n",
        "\n",
        "    # Select initial seed courses (5 from each department)\n",
        "    initial_courses1, mode_credit_sums = determine_initial_courses_single(subfield_data1)\n",
        "    initial_courses2, _ = determine_initial_courses_single(subfield_data2)\n",
        "    selected_topics = {**initial_courses1, **initial_courses2}  # 초기 과목 통합\n",
        "    selected_normalized_topics = {normalize_topic(topic) for topic in selected_topics}\n",
        "\n",
        "    # Create a biplot based on the entire data\n",
        "    B = create_bipartite_graph(combined_data)\n",
        "    cluster_topic_projection = project_cluster_topic_network(B)\n",
        "\n",
        "    # Calculate credits and averages\n",
        "    total_credits = sum(selected_topics.values())\n",
        "    avg_credits1 = subfield_data1.groupby('학교별 학과명')['학점'].sum().mean()\n",
        "    avg_credits2 = subfield_data2.groupby('학교별 학과명')['학점'].sum().mean()\n",
        "    jsd_ignored_once = False\n",
        "\n",
        "    # Add subject function\n",
        "    def add_course_to_double(ignore_jsd=False):\n",
        "        best_jsd, best_topic = float('inf'), None\n",
        "\n",
        "        for topic in cluster_topic_projection.nodes:\n",
        "            normalized_topic = normalize_topic(topic)\n",
        "            if (\n",
        "                normalized_topic in selected_normalized_topics\n",
        "                or any(excluded in normalized_topic for excluded in excluded_words)\n",
        "            ):\n",
        "                continue\n",
        "\n",
        "            # Calculate JSD average after adding temporary subjects\n",
        "            temp_selected_topics = selected_topics.copy()\n",
        "            temp_selected_topics[topic] = mode_credit_sums.get(topic, 3)\n",
        "            jsd1 = calculate_average_jsd(temp_selected_topics, subfield_data1)\n",
        "            jsd2 = calculate_average_jsd(temp_selected_topics, subfield_data2)\n",
        "            avg_jsd = (jsd1 + jsd2) / 2\n",
        "\n",
        "            # Update candidate\n",
        "            if ignore_jsd or avg_jsd < best_jsd:\n",
        "                best_jsd, best_topic = avg_jsd, topic\n",
        "\n",
        "        if best_topic:\n",
        "            selected_topics[best_topic] = mode_credit_sums.get(best_topic, 3)\n",
        "            selected_normalized_topics.add(normalize_topic(best_topic))\n",
        "            print(f\"Added course '{best_topic}' with new JSD: {best_jsd} (Ignore JSD: {ignore_jsd})\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    # Loop: run until credit requirement is met\n",
        "    while total_credits < min(0.85 * np.average(avg_credits1 + avg_credits2), 85):\n",
        "        if total_credits > min(0.85 * np.average(avg_credits1 + avg_credits2), 85):\n",
        "            break\n",
        "\n",
        "        # Add subjects taking JSD into account\n",
        "        added = add_course_to_double()\n",
        "\n",
        "        # call single if there are no candidates\n",
        "        if not added:\n",
        "            print(\"No valid double candidate. Adding single-mode courses.\")\n",
        "            optimized_combination_single(subfield1)\n",
        "            optimized_combination_single(subfield2)\n",
        "            continue  # Return to Double mode\n",
        "\n",
        "        # Update credits\n",
        "        total_credits = sum(selected_topics.values())\n",
        "\n",
        "    # Output the final result\n",
        "    final_topics_df = pd.DataFrame({\"Course\": list(selected_topics.keys()), \"Credits\": list(selected_topics.values())})\n",
        "    print(\"Final Topics for Combined Subfields:\")\n",
        "    print(final_topics_df)\n",
        "    print(f\"Total Credits: {total_credits}\")\n",
        "\n",
        "    return final_topics_df\n",
        "\n",
        "\n",
        "# sort all minor series in Korean alphabetical order (except N.C.E.)\n",
        "all_subfields = sorted([subfield for subfield in stem_data['표준분류소계열'].unique() if subfield != \"N.C.E.\"])\n",
        "\n",
        "# Generate 2 possible combinations from all subsequences\n",
        "combinations = list(itertools.combinations(all_subfields, 2))\n",
        "\n",
        "\n",
        "print(f\"Processing combination: {subfield1} & {subfield2}\")\n",
        "result_df = optimized_combination_double(subfield1, subfield2)\n",
        "filename = f\"/home/hedgehog/Interdisciplinary Majors/double_major/{subfield1}_{subfield2}_double_major.xlsx\"\n",
        "result_df.to_excel(filename, index=False)\n",
        "print(f\"Saved {filename}\")"
      ],
      "metadata": {
        "id": "EO4TngtesQux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}